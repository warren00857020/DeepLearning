{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9HySIpnbgdc76FwvxsTbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/warren00857020/DeepLearning/blob/main/DeepLearning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q2O3Ih5mmUIo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "data_dir = 'flowers'\n",
        "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "label_dict = {categories[i]: i for i in range(len(categories))}\n",
        "img_size = 128\n",
        "data = []\n",
        "target = []\n",
        "#需要將圖像轉換成數字矩陣，然後對其進行歸一化處理\n",
        "for category in categories:\n",
        "folder_path = os.path.join(data_dir, category)\n",
        "img_names = os.listdir(folder_path)\n",
        "for img_name in img_names:\n",
        "    img_path = os.path.join(folder_path, img_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    try:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        resized = cv2.resize(gray, (img_size, img_size))\n",
        "        data.append(resized)\n",
        "        target.append(label_dict[category])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Exception:\", e)\n",
        "#接下來 將資料轉換成numpy數組 並進行歸一化處理(將像素值縮放到0到1之間)\n",
        "data = np.array(data)/255.0\n",
        "data = np.reshape(data, (data.shape[0], img_size, img_size, 1))\n",
        "target = np.array(target)\n",
        "\n",
        "new_target = np_utils.to_categorical(target)\n",
        "\n",
        "data, new_target = shuffle(data, new_target, random_state=42)\n",
        "\n",
        "#建立模型 使用卷積神經網路\n",
        "model = Sequential()\n",
        "\n",
        "#新增一個卷積層，使用32個filter，3x3的kernel size，'relu'作為activation function\n",
        "model.add(Conv2D(32, (3, 3), input_shape=data.shape[1:], activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#新增一個卷積層，使用64個filter，3x3的kernel size，'relu'作為activation function\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#新增一個卷積層，使用128個filter，3x3的kernel size，'relu'作為activation function\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#新增一個卷積層，使用256個filter，3x3的kernel size，'relu'作為activation function\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "#新增一個全連接層，使用512個神經元，'relu'作為activation function\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#新增一個全連接層，使用256個神經元，'relu'作為activation function\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#新增一個final layer，使用5個神經元(分別代表每個類別)，'softmax'作為activation function\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "#使用'adam'optimizer、'categorical_crossentropy'loss function和'accuracy'度量標準來編譯模型。\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#使用我們的資料集對模型進行訓練\n",
        "history = model.fit(data, new_target, epochs=50, validation_split=0.1)\n",
        "\n",
        "#使用測試集來衡量模型的性能\n",
        "test_data = []\n",
        "test_target = []\n",
        "\n",
        "for category in categories:\n",
        "folder_path = os.path.join(data_dir, category)\n",
        "img_names = os.listdir(folder_path)\n",
        "for img_name in img_names:\n",
        "    img_path = os.path.join(folder_path, img_name)\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    try:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        resized = cv2.resize(gray, (img_size, img_size))\n",
        "        test_data.append(resized)\n",
        "        test_target.append(label_dict[category])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Exception:\", e)\n",
        "test_data = np.array(test_data)/255.0\n",
        "test_data = np.reshape(test_data, (test_data.shape[0], img_size, img_size, 1))\n",
        "test_target = np.array(test_target)\n",
        "\n",
        "new_test_target = np_utils.to_categorical(test_target)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_data, new_test_target)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# 取得測試集的predictions\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# 取得測試集的actual_labels\n",
        "actual_labels = [np.argmax(i) for i in new_test_target]\n",
        "\n",
        "# 取得預測的類別標籤\n",
        "predicted_labels = [np.argmax(i) for i in predictions]\n",
        "\n",
        "#印出confusion matrix and classification report\n",
        "print(confusion_matrix(actual_labels, predicted_labels))\n",
        "print(classification_report(actual_labels, predicted_labels))\n",
        "\n",
        "#印出actual and predicted class labels for 10 random test images\n",
        "for i in range(10):\n",
        "  index = random.randint(0, len(test_data) - 1)\n",
        "  print(\"Actual: \", categories[actual_labels[index]])\n",
        "  print(\"Predicted: \", categories[predicted_labels[index]])\n",
        "  plt.imshow(test_data[index], cmap='gray')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "id": "jSoTGb95H7h8"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}